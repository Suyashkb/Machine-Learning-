{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c85545",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-23T15:04:57.303991Z",
     "iopub.status.busy": "2023-08-23T15:04:57.303080Z",
     "iopub.status.idle": "2023-08-23T15:04:57.316055Z",
     "shell.execute_reply": "2023-08-23T15:04:57.315220Z"
    },
    "papermill": {
     "duration": 0.02871,
     "end_time": "2023-08-23T15:04:57.318231",
     "exception": false,
     "start_time": "2023-08-23T15:04:57.289521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a339f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:04:57.343713Z",
     "iopub.status.busy": "2023-08-23T15:04:57.342829Z",
     "iopub.status.idle": "2023-08-23T15:05:05.389984Z",
     "shell.execute_reply": "2023-08-23T15:05:05.388733Z"
    },
    "papermill": {
     "duration": 8.061999,
     "end_time": "2023-08-23T15:05:05.392166",
     "exception": false,
     "start_time": "2023-08-23T15:04:57.330167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import time \n",
    "import os\n",
    "path_to_file = tf.keras.utils.get_file(\n",
    "    \"shakespeare.txt\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",
    ")\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ccc71",
   "metadata": {
    "papermill": {
     "duration": 0.012282,
     "end_time": "2023-08-23T15:05:05.417299",
     "exception": false,
     "start_time": "2023-08-23T15:05:05.405017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imported the file and uploaded the data of shakespeare text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4795cdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:05.444160Z",
     "iopub.status.busy": "2023-08-23T15:05:05.443534Z",
     "iopub.status.idle": "2023-08-23T15:05:05.451908Z",
     "shell.execute_reply": "2023-08-23T15:05:05.450393Z"
    },
    "papermill": {
     "duration": 0.024282,
     "end_time": "2023-08-23T15:05:05.453983",
     "exception": false,
     "start_time": "2023-08-23T15:05:05.429701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "print(f\"Length of text: {len(text)} characters\")\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27b79e",
   "metadata": {
    "papermill": {
     "duration": 0.019743,
     "end_time": "2023-08-23T15:05:05.488348",
     "exception": false,
     "start_time": "2023-08-23T15:05:05.468605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Put the data into 'Text' and checked the first 250 words and printed the total number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f689a666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:05.537783Z",
     "iopub.status.busy": "2023-08-23T15:05:05.537450Z",
     "iopub.status.idle": "2023-08-23T15:05:05.571846Z",
     "shell.execute_reply": "2023-08-23T15:05:05.570482Z"
    },
    "papermill": {
     "duration": 0.058605,
     "end_time": "2023-08-23T15:05:05.574304",
     "exception": false,
     "start_time": "2023-08-23T15:05:05.515699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f\"{len(vocab)} unique characters\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76525b7",
   "metadata": {
    "papermill": {
     "duration": 0.012727,
     "end_time": "2023-08-23T15:05:05.600053",
     "exception": false,
     "start_time": "2023-08-23T15:05:05.587326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Sorted all the data and pulled out the unique characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a1a2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:05.626919Z",
     "iopub.status.busy": "2023-08-23T15:05:05.626121Z",
     "iopub.status.idle": "2023-08-23T15:05:08.365086Z",
     "shell.execute_reply": "2023-08-23T15:05:08.364117Z"
    },
    "papermill": {
     "duration": 2.755527,
     "end_time": "2023-08-23T15:05:08.368230",
     "exception": false,
     "start_time": "2023-08-23T15:05:05.612703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_texts = [\"abcdefg\", \"xyz\"]\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding=\"UTF-8\")\n",
    "chars\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06026213",
   "metadata": {
    "papermill": {
     "duration": 0.017291,
     "end_time": "2023-08-23T15:05:08.403909",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.386618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The text is vectorized here i.e. The letters are converted into vectors/tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3ba57",
   "metadata": {
    "papermill": {
     "duration": 0.017576,
     "end_time": "2023-08-23T15:05:08.439297",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.421721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Created StringLookup layer from tensorflow using tf.keras.layers.StringLookup adn inputed in ids_from_chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fbdd3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:08.477936Z",
     "iopub.status.busy": "2023-08-23T15:05:08.477452Z",
     "iopub.status.idle": "2023-08-23T15:05:08.497604Z",
     "shell.execute_reply": "2023-08-23T15:05:08.496750Z"
    },
    "papermill": {
     "duration": 0.043438,
     "end_time": "2023-08-23T15:05:08.500047",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.456609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f3a75",
   "metadata": {
    "papermill": {
     "duration": 0.017601,
     "end_time": "2023-08-23T15:05:08.535663",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.518062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It converts tokens to character ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cb5c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:08.571675Z",
     "iopub.status.busy": "2023-08-23T15:05:08.571212Z",
     "iopub.status.idle": "2023-08-23T15:05:08.593768Z",
     "shell.execute_reply": "2023-08-23T15:05:08.592912Z"
    },
    "papermill": {
     "duration": 0.043665,
     "end_time": "2023-08-23T15:05:08.596483",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.552818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d16584",
   "metadata": {
    "papermill": {
     "duration": 0.017326,
     "end_time": "2023-08-23T15:05:08.632047",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.614721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This layer recovers the characters from the vectors of IDs, and returns them as a 'tf.RaggedTensor' of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e552a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:08.671047Z",
     "iopub.status.busy": "2023-08-23T15:05:08.670561Z",
     "iopub.status.idle": "2023-08-23T15:05:08.683092Z",
     "shell.execute_reply": "2023-08-23T15:05:08.682264Z"
    },
    "papermill": {
     "duration": 0.033698,
     "end_time": "2023-08-23T15:05:08.685674",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.651976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2466db03",
   "metadata": {
    "papermill": {
     "duration": 0.017427,
     "end_time": "2023-08-23T15:05:08.720854",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.703427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "characters are joined back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74392c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:08.757849Z",
     "iopub.status.busy": "2023-08-23T15:05:08.757436Z",
     "iopub.status.idle": "2023-08-23T15:05:08.864373Z",
     "shell.execute_reply": "2023-08-23T15:05:08.863439Z"
    },
    "papermill": {
     "duration": 0.128828,
     "end_time": "2023-08-23T15:05:08.867488",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.738660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3d4be",
   "metadata": {
    "papermill": {
     "duration": 0.028107,
     "end_time": "2023-08-23T15:05:08.912920",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.884813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can tf.strings.reduce_join to join the characters back into strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b20253",
   "metadata": {
    "papermill": {
     "duration": 0.017903,
     "end_time": "2023-08-23T15:05:08.951776",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.933873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Prediction task**\n",
    "Creating training examples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2931b3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:08.991652Z",
     "iopub.status.busy": "2023-08-23T15:05:08.991079Z",
     "iopub.status.idle": "2023-08-23T15:05:09.837345Z",
     "shell.execute_reply": "2023-08-23T15:05:09.836131Z"
    },
    "papermill": {
     "duration": 0.871768,
     "end_time": "2023-08-23T15:05:09.841616",
     "exception": false,
     "start_time": "2023-08-23T15:05:08.969848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, \"UTF-8\"))\n",
    "all_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc4d34",
   "metadata": {
    "papermill": {
     "duration": 0.01296,
     "end_time": "2023-08-23T15:05:09.868321",
     "exception": false,
     "start_time": "2023-08-23T15:05:09.855361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " \n",
    "Each unicode is converted to a corresponding id using utf endcoding and converted to tensors(Tensors arae stored as all_ids)\n",
    "all_ids in next line displays the tensor/value in console of the program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39444b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:09.895524Z",
     "iopub.status.busy": "2023-08-23T15:05:09.895000Z",
     "iopub.status.idle": "2023-08-23T15:05:09.959734Z",
     "shell.execute_reply": "2023-08-23T15:05:09.958697Z"
    },
    "papermill": {
     "duration": 0.080556,
     "end_time": "2023-08-23T15:05:09.961852",
     "exception": false,
     "start_time": "2023-08-23T15:05:09.881296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db453dfd",
   "metadata": {
    "papermill": {
     "duration": 0.012714,
     "end_time": "2023-08-23T15:05:09.987579",
     "exception": false,
     "start_time": "2023-08-23T15:05:09.974865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ids_dataset creates a dataset consisting of all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86692cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.015509Z",
     "iopub.status.busy": "2023-08-23T15:05:10.014708Z",
     "iopub.status.idle": "2023-08-23T15:05:10.035094Z",
     "shell.execute_reply": "2023-08-23T15:05:10.034024Z"
    },
    "papermill": {
     "duration": 0.037197,
     "end_time": "2023-08-23T15:05:10.037622",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.000425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8b89c",
   "metadata": {
    "papermill": {
     "duration": 0.012875,
     "end_time": "2023-08-23T15:05:10.063592",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.050717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Batch method lets you easily convert these individual characters to sequences of the desired size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81bb380e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.090749Z",
     "iopub.status.busy": "2023-08-23T15:05:10.090468Z",
     "iopub.status.idle": "2023-08-23T15:05:10.107270Z",
     "shell.execute_reply": "2023-08-23T15:05:10.106248Z"
    },
    "papermill": {
     "duration": 0.033156,
     "end_time": "2023-08-23T15:05:10.109709",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.076553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5254887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.136990Z",
     "iopub.status.busy": "2023-08-23T15:05:10.136727Z",
     "iopub.status.idle": "2023-08-23T15:05:10.222569Z",
     "shell.execute_reply": "2023-08-23T15:05:10.221665Z"
    },
    "papermill": {
     "duration": 0.101934,
     "end_time": "2023-08-23T15:05:10.224691",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.122757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "split_input_target(list(\"Tensorflow\"))\n",
    "dataset = sequences.map(split_input_target)\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177d50e",
   "metadata": {
    "papermill": {
     "duration": 0.0131,
     "end_time": "2023-08-23T15:05:10.251252",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.238152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset created as (input,label)by adjusting a pointer one space to the right and training the model to predict the next possible character(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bae9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.279601Z",
     "iopub.status.busy": "2023-08-23T15:05:10.278814Z",
     "iopub.status.idle": "2023-08-23T15:05:10.293477Z",
     "shell.execute_reply": "2023-08-23T15:05:10.292467Z"
    },
    "papermill": {
     "duration": 0.031062,
     "end_time": "2023-08-23T15:05:10.295661",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.264599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a046cd",
   "metadata": {
    "papermill": {
     "duration": 0.013137,
     "end_time": "2023-08-23T15:05:10.322125",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.308988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is already spilt using tf.data earlier the batch size is getting defined and teh data is shuffled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf8ddc",
   "metadata": {
    "papermill": {
     "duration": 0.013153,
     "end_time": "2023-08-23T15:05:10.348586",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.335433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc71e1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.376781Z",
     "iopub.status.busy": "2023-08-23T15:05:10.375979Z",
     "iopub.status.idle": "2023-08-23T15:05:10.381643Z",
     "shell.execute_reply": "2023-08-23T15:05:10.380811Z"
    },
    "papermill": {
     "duration": 0.021939,
     "end_time": "2023-08-23T15:05:10.383753",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.361814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5275d8cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.411740Z",
     "iopub.status.busy": "2023-08-23T15:05:10.411455Z",
     "iopub.status.idle": "2023-08-23T15:05:10.420583Z",
     "shell.execute_reply": "2023-08-23T15:05:10.419575Z"
    },
    "papermill": {
     "duration": 0.026004,
     "end_time": "2023-08-23T15:05:10.422979",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.396975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        # TODO - Create an embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        # TODO - Create a GRU layer\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            rnn_units, return_sequences=True, return_state=True\n",
    "        )\n",
    "        # TODO - Finally connect it with a dense layer\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        # since we are training a text generation model,\n",
    "        # we use the previous state, in training. If there is no state,\n",
    "        # then we initialize the state\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5052835",
   "metadata": {
    "papermill": {
     "duration": 0.013074,
     "end_time": "2023-08-23T15:05:10.449375",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.436301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* tf.keras.layers.Embedding: The input layer. A trainable lookup table that will map each character-ID to a vector with embedding_dim dimensions;\n",
    "\n",
    "* tf.keras.layers.GRU: A type of RNN with size units=rnn_units (You can also use an LSTM layer here.);\n",
    "\n",
    "* tf.keras.layers.Dense: The output layer, with vocab_size outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model.\n",
    "\n",
    "The layers are defined in MyModel class under tf.keras.Model \n",
    "embedding and GRU layers used and connected with the dense layer \n",
    "self embedding done in the lower function \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb5e030e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.477309Z",
     "iopub.status.busy": "2023-08-23T15:05:10.476733Z",
     "iopub.status.idle": "2023-08-23T15:05:10.505442Z",
     "shell.execute_reply": "2023-08-23T15:05:10.504571Z"
    },
    "papermill": {
     "duration": 0.044869,
     "end_time": "2023-08-23T15:05:10.507458",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.462589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d0e9d",
   "metadata": {
    "papermill": {
     "duration": 0.013768,
     "end_time": "2023-08-23T15:05:10.534673",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.520905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Mymodel provided to a variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e26397b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:10.562456Z",
     "iopub.status.busy": "2023-08-23T15:05:10.562172Z",
     "iopub.status.idle": "2023-08-23T15:05:16.083898Z",
     "shell.execute_reply": "2023-08-23T15:05:16.083050Z"
    },
    "papermill": {
     "duration": 5.543409,
     "end_time": "2023-08-23T15:05:16.091389",
     "exception": false,
     "start_time": "2023-08-23T15:05:10.547980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\n",
    "        example_batch_predictions.shape,\n",
    "        \"# (batch_size, sequence_length, vocab_size)\",\n",
    "    )\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4676f3cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.121865Z",
     "iopub.status.busy": "2023-08-23T15:05:16.121558Z",
     "iopub.status.idle": "2023-08-23T15:05:16.136567Z",
     "shell.execute_reply": "2023-08-23T15:05:16.135233Z"
    },
    "papermill": {
     "duration": 0.032608,
     "end_time": "2023-08-23T15:05:16.138607",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.105999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 46, 49, 10, 16,  9, 23, 42, 51, 29,  6, 14, 40, 28, 62, 27,  1,\n",
       "        6, 29, 27, 54, 52, 64, 29, 65, 23, 31, 16, 44, 55, 50, 42, 15,  3,\n",
       "       50, 23, 58, 61, 46, 37, 14, 39, 23,  4, 40, 62,  9, 45, 65, 18, 43,\n",
       "       35, 64,  3, 42, 17, 62, 23, 55, 47, 37, 33,  5,  5,  0, 57, 40, 27,\n",
       "       58, 34, 38, 51, 38, 33, 33, 42, 25, 63, 51, 64, 52, 45, 20, 18, 63,\n",
       "       55, 32, 59, 51, 64, 20, 51, 37, 13, 16, 16, 25, 18, 31, 57])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    example_batch_predictions[0], num_samples=1\n",
    ")\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87c14ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.169476Z",
     "iopub.status.busy": "2023-08-23T15:05:16.169178Z",
     "iopub.status.idle": "2023-08-23T15:05:16.178391Z",
     "shell.execute_reply": "2023-08-23T15:05:16.177086Z"
    },
    "papermill": {
     "duration": 0.027161,
     "end_time": "2023-08-23T15:05:16.180403",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.153242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"p'st not so much for his death,\\nAs that the villain lives which slaughter'd him.\\n\\nJULIET:\\nWhat villa\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"\\ngj3C.JclP'AaOwN\\n'PNomyPzJRCepkcB!kJsvgXAZJ$aw.fzEdVy!cDwJphXT&&[UNK]raNsUYlYTTcLxlymfGExpStlyGlX?CCLERr\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9571498",
   "metadata": {
    "papermill": {
     "duration": 0.014354,
     "end_time": "2023-08-23T15:05:16.209294",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.194940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43498c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.240346Z",
     "iopub.status.busy": "2023-08-23T15:05:16.239700Z",
     "iopub.status.idle": "2023-08-23T15:05:16.264291Z",
     "shell.execute_reply": "2023-08-23T15:05:16.262948Z"
    },
    "papermill": {
     "duration": 0.042529,
     "end_time": "2023-08-23T15:05:16.266326",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.223797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.1910076, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\n",
    "    \"Prediction shape: \",\n",
    "    example_batch_predictions.shape,\n",
    "    \" # (batch_size, sequence_length, vocab_size)\",\n",
    ")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8195b7a",
   "metadata": {
    "papermill": {
     "duration": 0.014654,
     "end_time": "2023-08-23T15:05:16.296488",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.281834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Created a loss variable and used it on the last layer (shape);during initializatioan of model training the logits are supposed to be of close magnitudes to make sure the model is not overconfident while creating the early responses and the weights and biases initially not satisfactory enough .this ensures proper changes being registed while reducing the lost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4a0fb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.327360Z",
     "iopub.status.busy": "2023-08-23T15:05:16.326594Z",
     "iopub.status.idle": "2023-08-23T15:05:16.335464Z",
     "shell.execute_reply": "2023-08-23T15:05:16.334545Z"
    },
    "papermill": {
     "duration": 0.026218,
     "end_time": "2023-08-23T15:05:16.337392",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.311174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.08935"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc390c",
   "metadata": {
    "papermill": {
     "duration": 0.014541,
     "end_time": "2023-08-23T15:05:16.366859",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.352318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Checked Exponential mean to be approximately equal to the vocabulary size. Higher loss represents that model is sure about its wrong answers and the training is badly initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db6adc79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.398266Z",
     "iopub.status.busy": "2023-08-23T15:05:16.397498Z",
     "iopub.status.idle": "2023-08-23T15:05:16.413955Z",
     "shell.execute_reply": "2023-08-23T15:05:16.413095Z"
    },
    "papermill": {
     "duration": 0.034232,
     "end_time": "2023-08-23T15:05:16.415940",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.381708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7a37a",
   "metadata": {
    "papermill": {
     "duration": 0.014517,
     "end_time": "2023-08-23T15:05:16.445145",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.430628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model is compiled using Adam optimiser and the loss is registered all along wih default arguments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289dc6c",
   "metadata": {
    "papermill": {
     "duration": 0.015101,
     "end_time": "2023-08-23T15:05:16.474870",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.459769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Configuration of Checkpoints and Execution of training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7381b4a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.508218Z",
     "iopub.status.busy": "2023-08-23T15:05:16.507510Z",
     "iopub.status.idle": "2023-08-23T15:05:16.513082Z",
     "shell.execute_reply": "2023-08-23T15:05:16.512223Z"
    },
    "papermill": {
     "duration": 0.025666,
     "end_time": "2023-08-23T15:05:16.515137",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.489471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix, save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e8cc7",
   "metadata": {
    "papermill": {
     "duration": 0.014759,
     "end_time": "2023-08-23T15:05:16.544640",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.529881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Checkpoionts saved in a directory and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "300feaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:05:16.575807Z",
     "iopub.status.busy": "2023-08-23T15:05:16.575541Z",
     "iopub.status.idle": "2023-08-23T15:06:49.983337Z",
     "shell.execute_reply": "2023-08-23T15:06:49.982376Z"
    },
    "papermill": {
     "duration": 93.425479,
     "end_time": "2023-08-23T15:06:49.985539",
     "exception": false,
     "start_time": "2023-08-23T15:05:16.560060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 13s 43ms/step - loss: 2.7396\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 9s 38ms/step - loss: 2.0024\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 9s 39ms/step - loss: 1.7285\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 9s 39ms/step - loss: 1.5651\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 8s 38ms/step - loss: 1.4634\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 9s 38ms/step - loss: 1.3942\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 9s 38ms/step - loss: 1.3419\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 9s 38ms/step - loss: 1.2977\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 9s 38ms/step - loss: 1.2565\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 9s 38ms/step - loss: 1.2183\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e427e9",
   "metadata": {
    "papermill": {
     "duration": 0.078909,
     "end_time": "2023-08-23T15:06:50.146040",
     "exception": false,
     "start_time": "2023-08-23T15:06:50.067131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Total number of epochs 10 to makesure the amount of time is monitored and not too much "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85804c27",
   "metadata": {
    "papermill": {
     "duration": 0.07893,
     "end_time": "2023-08-23T15:06:50.304857",
     "exception": false,
     "start_time": "2023-08-23T15:06:50.225927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Generation of text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1b781",
   "metadata": {
    "papermill": {
     "duration": 0.078787,
     "end_time": "2023-08-23T15:06:50.462724",
     "exception": false,
     "start_time": "2023-08-23T15:06:50.383937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0828a59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:06:50.626144Z",
     "iopub.status.busy": "2023-08-23T15:06:50.622963Z",
     "iopub.status.idle": "2023-08-23T15:06:53.739111Z",
     "shell.execute_reply": "2023-08-23T15:06:53.737375Z"
    },
    "papermill": {
     "duration": 3.199366,
     "end_time": "2023-08-23T15:06:53.741294",
     "exception": false,
     "start_time": "2023-08-23T15:06:50.541928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "What think you may.\n",
      "\n",
      "PROSPERO:\n",
      "Since you says you are thoughts the proude companions,\n",
      "The drop of comfortuily.\n",
      "\n",
      "Shepherd:\n",
      "This wadusble time on this grod spoil,\n",
      "would you shall have her home, his one parlon, I'll\n",
      "make done to summ'd my subjects, believe!\n",
      "Money fall,\n",
      "To hail, or behalf a pouce, have maids\n",
      "That hath my chamber'd unliefully\n",
      "And grace away to 't.\n",
      "\n",
      "MONTAGUE:\n",
      "Why, dive, and mistress well and gid me never weep;\n",
      "For that I am infunilate.\n",
      "\n",
      "First Citizen:\n",
      "You are succeed for,--\n",
      "Had not hear? say. Pray yond consid, nor I were danger;\n",
      "The prency you all happiness to my choose.\n",
      "Now sting is scated: it is no ground,\n",
      "And honour'd by the state, and bet thy kindness\n",
      "Draws unson the morning gentleman did take\n",
      "A prenious eye if this regorted selves: if she see,\n",
      "This would plant thou that knows my daughter casting on his monagor.\n",
      "\n",
      "KING EDWARD IV:\n",
      "What, dough fates up how that have as me better.\n",
      "\n",
      "KING EDWARD IV:\n",
      "What word's war and knowledge when best gave hath been sleep?\n",
      "\n",
      "First Citizen: \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.0812602043151855\n"
     ]
    }
   ],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(\n",
    "            inputs=input_ids, states=states, return_state=True\n",
    "        )\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states\n",
    "    \n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([\"ROMEO:\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(\n",
    "        next_char, states=states\n",
    "    )\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
    "print(\"\\nRun time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c329f",
   "metadata": {
    "papermill": {
     "duration": 0.079428,
     "end_time": "2023-08-23T15:06:53.900735",
     "exception": false,
     "start_time": "2023-08-23T15:06:53.821307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 129.767858,
   "end_time": "2023-08-23T15:06:57.229256",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-23T15:04:47.461398",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
